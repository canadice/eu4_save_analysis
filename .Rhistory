stopCluster(cl)
information_finder <- function(vector, pattern){
if(pattern != "continent"){
if(!any(str_detect(vector, pattern))){
return(NA)
} else {
data <- vector[which(str_detect(vector, pattern))]
data <- unlist(str_split(data, pattern = "="))[2]
}
} else {
data <- vector[which(str_detect(vector, pattern))+1]
data <- str_trim(str_sub(data, start = 4), side = "right")
data <- str_extract(unlist(str_split(data, " ")), "[0-9]")
if(any(data == 1)){
data <- which(data == 1)[1]
} else {
return(NA)
}
}
return(data)
}
information_compiler <- function(x){
name <- str_extract(x[1], "[A-Z]{3}")
continent <- information_finder(x, "continent")
gov_rank <- information_finder(x, "government_rank")
development <- information_finder(x, "raw_development")
great_power <- information_finder(x, "great_power_score")
cur_treasury <- information_finder(x, "treasury=")
est_month_income <- information_finder(x, "estimated_monthly_income")
mil_strength <- information_finder(x, "military_strength=")
manpower <- information_finder(x, "max_manpower=")
cur_army_size <- information_finder(x, "num_of_regulars")
data <- cbind(name, continent, gov_rank, development, great_power, cur_treasury, est_month_income, mil_strength, manpower, cur_army_size)
return(data)
}
data <- data.frame(matrix(unlist(lapply(country_data_split, FUN = information_compiler)), ncol=10, byrow=TRUE))
data[,4:10] <- apply(apply(data[,4:10], MARGIN = 2, FUN = as.character), MARGIN = 2, FUN = as.numeric)
colnames(data) <- c("Tag", "continent",
"government_rank", "development",
"great_power", "cur_treasury",
"est_month_income", "mil_strength",
"manpower", "cur_army_size")
data <- data %>% inner_join(tags)
data[which(!is.na(data$continent)), ]
data <- data[which(!is.na(data$continent)), ]
game_data <- data
game_data$Army <- rep(NA, nrow(game_data))
game_data$Army[1:3] <- c("Axis", "Allies", "Allies")
game_data_table <- aggregate.data.frame(game_data[, 4:10],
by = list(game_data$Army),
FUN = sum)
game_data_table
colnames(game_data_table) <- c("Army", "development",
"great_power", "cur_treasury",
"est_month_income", "mil_strength",
"manpower", "cur_army_size")
ggplot(data = game_data_table) + aes(x = "", y = manpower, fill = Army) +
geom_bar(stat = "identity", width = 1, color = "black") +
scale_fill_manual(values = c("#c0c0c0", "#E69F00")) + theme_bw() +
scale_x_discrete(breaks = NULL) + scale_y_continuous(expand = c(0,0), breaks = NULL) +
coord_polar(theta = "y", start = 0) +
labs(x = NULL, y = NULL, title = "Manpower") +
theme(panel.grid = element_blank(), panel.border = element_blank(),
plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
legend.title = element_text(face = "bold"))
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
game_data_table
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
game_data$Army <- rep(NA, nrow(game_data))
game_data$Army[which(game_data$Nation %in% input$axis)] <- input$team_1
game_data$Army[1:3] <- input$team_1
game_data$Army[4:8] <- input$team_2
game_data_table <- aggregate.data.frame(game_data[, 4:10],
by = list(game_data$Army),
FUN = sum, na.rm = TRUE)
game_data_table
colnames(game_data_table) <- c("Army", "development",
"great_power", "cur_treasury",
"est_month_income", "mil_strength",
"manpower", "cur_army_size")
ggplot(data = game_data_table) + aes(x = "", y = manpower, fill = Army) +
geom_bar(stat = "identity", width = 1, color = "black") +
scale_fill_manual(values = c("#c0c0c0", "#E69F00")) + theme_bw() +
scale_x_discrete(breaks = NULL) + scale_y_continuous(expand = c(0,0), breaks = NULL) +
coord_polar(theta = "y", start = 0) +
labs(x = NULL, y = NULL, title = "Manpower") +
theme(panel.grid = element_blank(), panel.border = element_blank(),
plot.title = element_text(hjust = 0.5, size = 15, face = "bold"),
legend.title = element_text(face = "bold"))
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
shiny::runApp(display.mode="showcase")
shiny::runApp(appDir = "F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator",display.mode="showcase")
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
aggData()
game_data <- getData()
game_data$Army <- rep(NA, nrow(game_data))
game_data$Army[which(game_data$Nation %in% input$axis)] <- input$team_1
game_data$Army[which(game_data$Nation %in% input$allies)] <- input$team_2
game_data_table <- aggregate.data.frame(game_data[, 4:10],
by = list(game_data$Army),
FUN = sum, na.rm = TRUE)
game_data_table
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
runApp('F:/Google Drive/Paradox Games/R-Functions/EU4_Force_Calculator')
c(1:7)
c(1:7, 11:17, 21:27, 31:37, 41:47)
shiny::runApp('F:/GitHubs/number_scanner')
runApp('F:/GitHubs/number_scanner')
require(xtable)
48/1081
source(paste(dir, "/combinatorics_solver.R", sep = ""))
dir <- "F:/OneDrive/OneDrive - Linköpings universitet/Jobb/LiU/Programming/Automatic Examination + Solutions"
source(paste(dir, "/combinatorics_solver.R", sep = ""))
rep(4, 13)
permutations(n = n, k = k, k.ident = rep(4, 13))
n <- 52
k <- 10
permutations(n = n, k = k, k.ident = rep(4, 13))
permutations(n = n, k.ident = rep(2, 13))
permutations(n = n, k.ident = rep(2, 13))
n <- 26
permutations(n = n, k.ident = rep(2, 13))
source(paste(dir, "/probability_solver.R", sep = ""))
source(paste(dir, "/set_theory_solver.R", sep = ""))
13/52
(13/52)*(4/52)
1/52
52*13
52*4
208/676
52*52
13*4
seed <- 16735872
seed_ans <- seed
require(xtable, quietly = TRUE)
n <- 45
set.seed(seed)
x <- floor(runif(n, min = 5, max = 25))
set.seed(seed+312)
y <- floor(1.5*x + rnorm(length(x), sd = 5))
set.seed(seed+ 152)
y2 <- floor(1*x + rnorm(length(x), sd = 10))
x.mean <- cbind(mean(y), mean(y2))
x.sigma <- cbind(sd(y), sd(y2))
x.n <- rep(n, 2)
data <- as.data.frame(rbind(x.mean, x.sigma, x.n))
rownames(data) <- c("Medelvärde", "Standardavvikelse", "Antal")
colnames(data) <- c("Grupp 1", "Grupp 2")
print(xtable(data, digits = c(1, rep(3, ncol(data)))), comment = FALSE, include.colnames = TRUE)
true <- paste("$", round(-diff(t(x.mean)) - qt(p = 0.975, df = sum(x.n)-2) * sqrt(sum(x.sigma^2/n)), 3), "\\le \\mu_1 - \\mu_2 \\le", round(-diff(t(x.mean)) + qt(p = 0.975, df = sum(x.n)-2) * sqrt(sum(x.sigma^2/n)), 3), "$", sep = "")
n <- 321
x <- 29
p <- x/n
pi_0 <- 0.125
z_test <- (p-pi_0)/(sqrt((pi_0*(1-pi_0))/n))
true <- paste("Kritiska värdet är -1.64, $H_0$ förkastas.")
set.seed(seed + 214768)
obs <- round(runif(5, min = 3, max = 10), 0)
true <- rep(sum(obs)/length(obs), length(obs))
300*(30000/(30000+32000/sqrt(2)))
300*((32000/sqrt(2))/(30000+32000/sqrt(2)))
dir <- "F:/OneDrive/OneDrive - Linköpings universitet/Jobb/LiU/Programming/Automatic Examination + Solutions"
source(paste(dir, "/probability_solver.R", sep = ""))
source(paste(dir, "/probability_solver.R", sep = ""))
hypergeometric(n = n, pi = pi, x = x, N = N, side = "le")
source(paste(dir, "/probability_solver.R", sep = ""))
hypergeometric(n = n, pi = pi, x = x, N = N, side = "le")
hypergeometric(n = n, pi = pi, x = x, N = N, side = "le")
source(paste(dir, "/probability_solver.R", sep = ""))
x = 5
n = 10
N = 25
dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
pi = 0.33
pi * N
N-(pi*N)
dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
x = 2
prob <- dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
m = pi * N
n = N-(pi*N)
k = n
prob <- dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
N = 30
dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
n = 10
dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
pi * N
pi <- 1/3
prob <- dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
dhyper(x = x, m = pi * N, n = N-(pi*N), k = n)
choose(10, 5)
choose(10, 5)*choose(20, 5)/choose(30, 10)
source(paste(dir, "/confidence_intervals_solver.R", sep = ""))
mean.ci(x.mean = mu, x.sigma = sigma, x.n = n, alpha = alpha, side = "ne", N = N, total = TRUE, wahlin = TRUE)
N <- 50
n <- 10
mu <- 31.2
sigma <- 1.6
alpha <- 0.1
mean.ci(x.mean = mu, x.sigma = sigma, x.n = n, alpha = alpha, side = "ne", N = N, total = TRUE, wahlin = TRUE)
library(png)
library(grid)
choose(n = 4, k = )
choose(n = 4, k = 3)
choose(n = 49, k = 2)
round(13*choose(4, 3)*choose(49, 2)/choose(52, 5)*100, 3)
cat(paste("$$ \\frac{Tre~av~samma~valör}{Antalet~olika~dragningar} = \\frac{13 \\cdot C^{3}_{4} \\cdot C^{2}_{49}}{C^{5}_{52}} = \\frac{ 13 \\cdot", choose(4, 3), " \\cdot ", choose(49, 2), "}{ ", choose(52, 5)"} \\approx ", round(13*choose(4, 3)*choose(49, 2)/choose(52, 5)*100, 3)," ~procent $$"))
51238/69762
36.67/7.82
shiny::runApp('F:/GitHubs/eu4_save_analysis')
sqrt(0.12*0.88/100)
1.96*sqrt(0.12*0.88/100)
1.96*sqrt(0.45*0.55/100)
12*52/120
TENTA <- function(X){
RESULTAT <- X >= 12
UELLERG  <-"  ##TRUE - G##FALSE - U## RESULTAT = "
print(c(UELLERG, RESULTAT))
}
TENTA(13)
45*6/105
26*6/105
34*6/105
2/9
a<-readLines("https://github.com/Stickheadz32/Clone-Hero-custom-charts/raw/master/All%20for%20One%20-%20Stryper/notes.chart")
length<-length(a)
b<-c()
for(i in 1:length){
d<-a[i]
regex<-grepl("[\\[][a-zA-Z]+[\\]$]",d,perl=T)
if(regex){
b<-c(b,d)
}
}
b
a
# Logical if solutions are included in the file
solutions <- TRUE
# dir <- "D:/OneDrive/OneDrive - Linköpings universitet/Jobb/LiU/Programming/Automatic Examination + Solutions"
dir <- "F:/OneDrive/OneDrive - Linköpings universitet/Jobb/LiU/Programming/Automatic Examination + Solutions"
require(xtable, quietly = TRUE)
options(scipen=999)
options(xtable.comment = FALSE,
xtable.table.placement="H")
seed <- 187518
n <- 100
set.seed(seed)
x <- rnorm(n = n-12, mean = 10, sd = 8)
set.seed(seed+312)
y <- rnorm(n = n-8, mean = 14, sd = 10)
x.mean <- cbind(mean(x), mean(y))
x.sigma <- cbind(sd(x), sd(y))
x.n <- cbind(length(x), length(y))
data <- as.data.frame(rbind(x.mean, x.sigma, x.n))
rownames(data) <- c("Medelvärde", "Standardavvikelse", "Antal")
colnames(data) <- c("Dator", "TV-spel")
print(xtable(data, digits = c(1, rep(2, ncol(data)))), comment = FALSE, include.colnames = TRUE)
source(paste(dir, "/hypothesis_solver.R", sep = ""))
source(paste(dir, "/hypothesis_solver.R", sep = ""))
mean.test(x.mean = x.mean[1], x.sigma = x.sigma[1], x.n = x.n[1], mu0 = 12, alpha = 0.05, side = >, wahlin = TRUE)
mean.test(x.mean = x.mean[1], x.sigma = x.sigma[1], x.n = x.n[1], mu0 = 12, alpha = 0.05, side = ">", wahlin = TRUE)
mean.dif.test(x.mean = x.mean, x.sigma = x.sigma, x.n = x.n, d0 = 0, wahlin = TRUE)
source(paste(dir, "/confidence_intervals_solver.R", sep = ""))
mean.dif.ci(x.mean = x.mean, x.sigma = x.sigma, x.n = x.n, d0 = 0, wahlin = TRUE)
mean.diff.ci(x.mean = x.mean, x.sigma = x.sigma, x.n = x.n, d0 = 0, wahlin = TRUE)
mean.diff.ci(x.mean = x.mean, x.sigma = x.sigma, x.n = x.n, wahlin = TRUE)
source(paste(dir, "/probability_solver.R", sep = ""))
freq["Man", ]
row <- col <- 2
set.seed(seed + 3)
freq <- matrix(floor(runif(n = row * col, min = 45, max = 100)), nrow = row, ncol = col)
colnames(freq) <- c("Coop", "ICA")
rownames(freq) <- c("Man", "Kvinna")
freq["Man", ]
binomial(n = n, pi = sum(freq["Man", ])/sum(freq), x = 5, side = "ge")
n <- 10
x <- 5
binomial(n = n, pi = round(sum(freq["Man", ])/sum(freq), 3), x = 5, side = "ge")
options(shiny.maxRequestSize = 60*1024^2)
setwd("F:/GitHubs/eu4_save_analysis")
source("save_scraper.R")
source("data_compiler.R")
library(shiny, quietly = TRUE)
library(shinythemes, quietly = TRUE)
library(stringr, quietly = TRUE)
require(ggplot2, quietly = TRUE)
require(dplyr, quietly = TRUE)
require(tidyr, quietly = TRUE)
require(stringr, quietly = TRUE)
require(parallel, quietly = TRUE)
require(shinycssloaders, quietly = TRUE)
save <- readLines(con = "C:/Users/Canadice/Documents/Paradox Interactive/Europa Universalis IV/save games/Clash of Europe 1.eu4", encoding = "ANSI", warn = FALSE)
game_data <- save_processing(save)
source("data_compiler.R")
tags <- read.csv2("tags.csv")
end <- which(str_detect(save, pattern = "^trade"))[1]
meta <- save[1:(end - 1)]
start_country <- which(str_detect(save, pattern = "^countries=\\{"))
country_data <- save[start_country:(which(str_detect(save, pattern = "active_advisors=\\{"))-1)]
starts <- which(str_detect(country_data, pattern = "^\t[A-Z]{3}=\\{"))
ends <- c((starts-1)[-1], length(country_data))
indices <- do.call(list, mapply(seq, starts, ends))
country_data_split <- lapply(indices, FUN = function(x){country_data[x]})
starts_provinces <- which(str_detect(save, pattern = "^-[0-9]+=\\{"))
ends_provinces <- c((starts_provinces-1)[-1], start_country-1)
indices <- do.call(list, mapply(seq, starts_provinces, ends_provinces))
province_data_split <- lapply(indices, FUN = function(x){save[x]})
rm(list = c("ends", "end", "starts", "starts_provinces", "ends_provinces", "start_country", "indices", "save"))
meta_data <- meta_information_scraper(vector = meta)
cl <- makeCluster(getOption("cl.cores", 4))
meta
vector = meta
information_indices <- str_detect(vector, pattern = "=") & !str_detect(vector, pattern = "[{}]")
information <- vector[information_indices]
clean_information <- str_replace_all(information, pattern = "[\t\"]", replacement = "")
clean_information <- clean_information[!(str_detect(clean_information, "[0-9]{4}\\.[0-9]{1,2}\\.[0-9]") &
!str_detect(clean_information, pattern = "date"))]
clean_information_matrix <- matrix(unlist(str_split(string = clean_information, pattern = "=")),
ncol = length(clean_information),
byrow = FALSE)
clean_information_matrix <- clean_information_matrix[,!(clean_information_matrix[1,] %in% c("value", "id", "comparison", "localization", "key", "selector", "sample_count"))]
var_names <- clean_information_matrix[1,]
if(sum(var_names %in% "date")>1){
clean_information_matrix <- clean_information_matrix[,-which(var_names == "date")[2]]
var_names <- var_names[-which(var_names == "date")[2]]
}
clean_information_data <- as.data.frame(t(data.frame(values = clean_information_matrix[2,], row.names = var_names)), stringsAsFactors = FALSE)
var_names
clean_information_matrix <- clean_information_matrix[,!(clean_information_matrix[1,] %in% c("value", "id", "comparison", "localization",
"key", "selector", "sample_count", "sample_value"))]
var_names <- clean_information_matrix[1,]
if(sum(var_names %in% "date")>1){
clean_information_matrix <- clean_information_matrix[,-which(var_names == "date")[2]]
var_names <- var_names[-which(var_names == "date")[2]]
}
clean_information_data <- as.data.frame(t(data.frame(values = clean_information_matrix[2,], row.names = var_names)), stringsAsFactors = FALSE)
num_indices <- sapply(clean_information_data, FUN = function(x){!is.na(suppressWarnings(as.numeric(x)))})
clean_information_data[,num_indices] <- sapply(clean_information_data[,num_indices], FUN = as.numeric)
source("data_compiler.R")
meta_data <- meta_information_scraper(vector = meta)
game_data <- save_processing(save)
# Sources the different functions needed
source("data_compiler.R")
# Imports a list of tags and responding names of nation
tags <- read.csv2("tags.csv")
##########################################################################
### Subsetting
##########################################################################
############################
### META
############################
### Starts the splitting for meta-data
# The first part of data existing in the save is trade, meta-data is located above
end <- which(str_detect(save, pattern = "^trade"))[1]
meta <- save[1:(end - 1)]
############################
### Country
############################
### Splits the save file into the nations parts, starting at the first nation
### Last list object contains the last nation information + all the rest of the save...
# Detects where to start looking for country data
start_country <- which(str_detect(save, pattern = "^countries=\\{"))
# Detects position of } as it defines end of information block.
# As the game progresses, } without any tabs are inserted resulting in the following
# solution to make the last list-object takes the whole rest of the save to the end.
# Subsets just the country data, might be unecessary.
# 1.23 added active advisors to the save which screws with finding positions of nations' tags
country_data <- save[start_country:(which(str_detect(save, pattern = "active_advisors=\\{"))-1)]
# Same as above with provinces
starts <- which(str_detect(country_data, pattern = "^\t[A-Z]{3}=\\{"))
ends <- c((starts-1)[-1], length(country_data))
indices <- do.call(list, mapply(seq, starts, ends))
country_data_split <- lapply(indices, FUN = function(x){country_data[x]})
############################
### Province
############################
### Splits the save file into the province parts, starting at the first province
### Last list object contains the last province information + all the rest of the save...
# Detects where to start the individual province data
starts_provinces <- which(str_detect(save, pattern = "^-[0-9]+=\\{"))
# As starts portion off the different provinces, ends are the one line before
# The list of provinces end where countries start so the last province will end on the line before
ends_provinces <- c((starts_provinces-1)[-1], start_country-1)
# Splits the data into a list of their individual province information
indices <- do.call(list, mapply(seq, starts_provinces, ends_provinces))
province_data_split <- lapply(indices, FUN = function(x){save[x]})
############################
### Cleaning
############################
# Removes original save and indices to save at least some working space
rm(list = c("ends", "end", "starts", "starts_provinces", "ends_provinces", "start_country", "indices", "save"))
##########################################################################
### Structuring & scraping
##########################################################################
############################
### Meta data
############################
meta_data <- meta_information_scraper(vector = meta)
save <- readLines(con = "C:/Users/Canadice/Documents/Paradox Interactive/Europa Universalis IV/save games/Clash of Europe 1.eu4", encoding = "ANSI", warn = FALSE)
# Sources the different functions needed
source("data_compiler.R")
# Imports a list of tags and responding names of nation
tags <- read.csv2("tags.csv")
##########################################################################
### Subsetting
##########################################################################
############################
### META
############################
### Starts the splitting for meta-data
# The first part of data existing in the save is trade, meta-data is located above
end <- which(str_detect(save, pattern = "^trade"))[1]
meta <- save[1:(end - 1)]
############################
### Country
############################
### Splits the save file into the nations parts, starting at the first nation
### Last list object contains the last nation information + all the rest of the save...
# Detects where to start looking for country data
start_country <- which(str_detect(save, pattern = "^countries=\\{"))
# Detects position of } as it defines end of information block.
# As the game progresses, } without any tabs are inserted resulting in the following
# solution to make the last list-object takes the whole rest of the save to the end.
# Subsets just the country data, might be unecessary.
# 1.23 added active advisors to the save which screws with finding positions of nations' tags
country_data <- save[start_country:(which(str_detect(save, pattern = "active_advisors=\\{"))-1)]
# Same as above with provinces
starts <- which(str_detect(country_data, pattern = "^\t[A-Z]{3}=\\{"))
ends <- c((starts-1)[-1], length(country_data))
indices <- do.call(list, mapply(seq, starts, ends))
country_data_split <- lapply(indices, FUN = function(x){country_data[x]})
############################
### Province
############################
### Splits the save file into the province parts, starting at the first province
### Last list object contains the last province information + all the rest of the save...
# Detects where to start the individual province data
starts_provinces <- which(str_detect(save, pattern = "^-[0-9]+=\\{"))
# As starts portion off the different provinces, ends are the one line before
# The list of provinces end where countries start so the last province will end on the line before
ends_provinces <- c((starts_provinces-1)[-1], start_country-1)
# Splits the data into a list of their individual province information
indices <- do.call(list, mapply(seq, starts_provinces, ends_provinces))
province_data_split <- lapply(indices, FUN = function(x){save[x]})
############################
### Cleaning
############################
# Removes original save and indices to save at least some working space
rm(list = c("ends", "end", "starts", "starts_provinces", "ends_provinces", "start_country", "indices", "save"))
##########################################################################
### Structuring & scraping
##########################################################################
############################
### Meta data
############################
meta_data <- meta_information_scraper(vector = meta)
meta_data
# Compiles the province data to a list, parallel processing to speed the list up
cl <- makeCluster(getOption("cl.cores", 4))
clusterExport(cl, varlist = c("information_finder", "province_information_scraper"))
data <- parLapply(cl = cl, X = province_data_split, fun = province_information_compiler)
stopCluster(cl)
# Takes all information in the list and concatenate into a data frame
province_data <- data %>%
Reduce(function(dtf1,dtf2) suppressWarnings(bind_rows(dtf1,dtf2)), .)
###############
### Structure
###############
# Finds the column index for sorting
buildings <- which(colnames(province_data) %in% c("marketplace", "workshop", "temple", "barracks", "shipyard", "fort_15th",
"courthouse", "dock", "regimental_camp", "fort_16th",
"cathedral", "university", "trade_depot", "grand_shipyard", "training_fields", "fort_17th",
"stock_exchange", "counting_house", "town_hall", "drydock", "conscription_center", "fort_18th",
"wharf", "weapons", "textile", "plantations", "tradecompany")
)
fort <- which(str_detect(colnames(x = province_data), pattern = "^fort_inf"))
cores <- which(str_detect(colnames(x = province_data), pattern = "^core"))
claims <- which(str_detect(colnames(x = province_data), pattern = "^claim"))
base <- which(str_detect(colnames(x = province_data), pattern = "^base"))
PID <- which(str_detect(colnames(x = province_data), pattern = "^PID"))
originals <- which(str_detect(colnames(x = province_data), pattern = "^original"))
info <- which(colnames(province_data) %in% c("name", "culture", "religion", "capital", "trade_goods", "trade_power",
"trade", "local_autonomy", "hre", "owner")
)
ordering_index <- c(PID, info, base, buildings, fort, cores, claims, originals)
province_data <- province_data[,c(ordering_index, (1:ncol(province_data))[-ordering_index])]
############################
### Country data
############################
# Compiles the country data to a list
cl <- makeCluster(getOption("cl.cores", 4))
clusterExport(cl, varlist = c("information_finder"))
data <- parLapply(cl = cl, X = country_data_split, fun = country_information_compiler)
stopCluster(cl)
# Takes all information in the list and concatenate into a data frame
country_data <- data %>%
Reduce(function(dtf1,dtf2) suppressWarnings(bind_rows(dtf1,dtf2)), .)
# Merges with the province data for each of the countries' capitals
country_data <- country_data %>% left_join(province_data[, c("PID", "hre")], by = c("capital" = "PID"))
# Merges with the country name data from tags
country_data <- country_data %>% inner_join(tags, by = c("tag" = "Tag"))
ind <- c("tag", "Name")
country_data <- country_data[, c(ind, colnames(country_data)[!colnames(country_data) %in% ind])]
# Subsets nations that exist at the current save
country_data <- country_data[which(country_data$capped_development > 0),]
resulting_data <- list(meta = meta_data, province = province_data, country = country_data)
save <- readLines(con = "C:/Users/Canadice/Documents/Paradox Interactive/Europa Universalis IV/save games/Clash of Europe 1.eu4", encoding = "ANSI", warn = FALSE)
game_data <- save_processing(save)
save(game_data, file = "latest_Europe_domination.RData")
runApp()
